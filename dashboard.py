# ======= imports =======
import os
import json
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.io as pio
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns

from joblib import load, dump
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             confusion_matrix, ConfusionMatrixDisplay,
                             precision_recall_curve, auc, silhouette_score)
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

try:
    from lightgbm import LGBMClassifier
    HAS_LGBM = True
except Exception:
    HAS_LGBM = False

# ======= Streamlit base config =======
st.set_page_config(page_title="HR Attrition Dashboard", layout="wide", page_icon="ğŸ“Š")
st.caption("Made by Abolfazl Asjadi | contact: https://t.me/Abolfazl_A1256")

# ======= UI defaults =======
pio.templates.default = "plotly_dark"
BASE_FONT = dict(family="Segoe UI, Vazirmatn, IRANSans, Arial", size=13)
ATTRITION_COLORS = {"Yes": "#E74C3C", "No": "#1f77b4"}   # Red=Leave, Blue=Stay

# ======= CSS for top nav =======
st.markdown(
    """
    <style>
    div[data-baseweb="radio"] > div { flex-direction: row; justify-content: center; gap: .75rem; flex-wrap: wrap; }
    div[data-baseweb="radio"] label {
        background: #14171f; padding: 8px 14px; border-radius: 10px; color: #fff;
        font-weight: 600; border: 1px solid #3a3f47; transition: .2s;
    }
    div[data-baseweb="radio"] label:hover { border-color:#4CAF50; box-shadow: 0 0 0 2px rgba(76,175,80,.25); }
    div[data-baseweb="radio"] input:checked + div { background: #4CAF50 !important; color: #fff !important; }
    [data-testid="stMetricValue"] { font-size: 42px; }
    [data-testid="stMetricDelta"] { font-size: 14px; }
    </style>
    """,
    unsafe_allow_html=True
)

# ======= helper figs =======
def pretty_layout(fig, height=840):
    fig.update_layout(
        height=height,
        margin=dict(t=80, r=20, b=40, l=50),
        font=BASE_FONT,
        legend=dict(orientation="h", y=1.08, x=0, title=""),
        hoverlabel=dict(bgcolor="#121319", font_size=12, font_color="white"),
        bargap=0.25,
        plot_bgcolor="#0f1117",
        paper_bgcolor="#0f1117",
    )
    return fig

def show_fig(fig, height=460):
    fig.update_layout(
        height=height,
        margin=dict(t=60, r=20, b=40, l=50),
        font=BASE_FONT,
        plot_bgcolor="#0f1117",
        paper_bgcolor="#0f1117",
        legend=dict(orientation="h", y=1.08, x=0, title="")
    )
    st.plotly_chart(fig, use_container_width=True)

# ======= constants =======
MODEL_PATH = r"C:\Users\asjadi\Desktop\project\best_model.joblib"
RANDOM_STATE = 42

# ======= data loading =======
@st.cache_data
def load_df_from_upload(file):
    if file is None:
        try:
            return pd.read_excel("IBM HR.xlsx", sheet_name="IBM HR")
        except Exception:
            return None
    if file.name.lower().endswith(".csv"):
        return pd.read_csv(file)
    return pd.read_excel(file)

# ======= ML helpers =======
def build_preprocess(X: pd.DataFrame):
    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = X.select_dtypes(include=["object", "category"]).columns.tolist()
    try:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)

    numeric = Pipeline([("imputer", SimpleImputer(strategy="median")),
                        ("scaler", StandardScaler())])
    categorical = Pipeline([("imputer", SimpleImputer(strategy="most_frequent")),
                            ("onehot", ohe)])

    return ColumnTransformer([("num", numeric, num_cols),
                              ("cat", categorical, cat_cols)],
                             remainder="drop")

def fit_and_eval_all(X, y):
    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
    )
    preprocess = build_preprocess(X)

    models = {
        "LogReg": LogisticRegression(max_iter=1000, class_weight="balanced", random_state=RANDOM_STATE),
        "DecisionTree": DecisionTreeClassifier(class_weight="balanced", random_state=RANDOM_STATE),
        "RandomForest": RandomForestClassifier(n_estimators=300, class_weight="balanced", random_state=RANDOM_STATE),
        "KNN": KNeighborsClassifier(n_neighbors=11),
    }
    param_grid = {
        "LogReg": {"clf__C": [0.1, 1, 3]},
        "DecisionTree": {"clf__max_depth": [4, 6, 10, None], "clf__min_samples_split": [2, 10, 20]},
        "RandomForest": {"clf__n_estimators": [200, 300], "clf__max_depth": [None, 8, 14]},
        "KNN": {"clf__n_neighbors": [5, 9, 11, 15]},
    }
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

    results, best_estimators, pr_curves = [], {}, {}
    for name, clf in models.items():
        pipe = Pipeline([("prep", preprocess), ("clf", clf)])
        gs = GridSearchCV(pipe, param_grid[name], scoring="f1", cv=cv, n_jobs=-1)
        gs.fit(X_tr, y_tr)

        best_estimators[name] = gs.best_estimator_
        y_pred = gs.predict(X_te)
        y_prob = gs.predict_proba(X_te)[:, 1]

        acc = accuracy_score(y_te, y_pred)
        pre = precision_score(y_te, y_pred, zero_division=0)
        rec = recall_score(y_te, y_pred, zero_division=0)
        f1  = f1_score(y_te, y_pred, zero_division=0)

        precision, recall, _ = precision_recall_curve(y_te, y_prob)
        pr_auc = auc(recall, precision)
        pr_curves[name] = (precision, recall, pr_auc)

        results.append({"model": name, "best_params": gs.best_params_,
                        "Accuracy": acc, "Precision": pre, "Recall": rec, "F1": f1, "PR_AUC": pr_auc})

    res_df = pd.DataFrame(results).sort_values("F1", ascending=False)
    best_name = res_df.iloc[0]["model"]
    return res_df, best_estimators[best_name], (X_tr, X_te, y_tr, y_te), pr_curves

def predict_with_pipeline(mdl, sample_dict, threshold=0.3):
    prep = mdl.named_steps.get("prep", None)
    cols = list(prep.feature_names_in_) if (prep is not None and hasattr(prep, "feature_names_in_")) else None
    if cols is None:
        raise ValueError("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯Ù†Ø¯.")

    # detect numeric/categorical
    num_cols, cat_cols = [], []
    if hasattr(prep, "transformers_"):
        for name, _, cols_sel in prep.transformers_:
            if name == "num": num_cols = list(cols_sel)
            if name == "cat": cat_cols = list(cols_sel)

    # build complete row
    row = {c: np.nan for c in cols}
    for k, v in sample_dict.items():
        if k in row:
            row[k] = v
    X_input = pd.DataFrame([row], columns=cols)

    for c in num_cols:
        if c in X_input: X_input[c] = pd.to_numeric(X_input[c], errors="coerce")
    for c in cat_cols:
        if c in X_input: X_input[c] = X_input[c].astype("object")

    prob = mdl.predict_proba(X_input)[0, 1]
    label = "Leave" if prob >= threshold else "Stay"
    return label, float(prob)

# ======= DATA IN =======
st.sidebar.header("1) Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡")
uploaded = st.sidebar.file_uploader("CSV ÛŒØ§ Excel", type=["csv", "xlsx"])
df = load_df_from_upload(uploaded)

if df is None:
    st.info("Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†.")
    st.stop()

df["_Attrition"] = (df["Attrition"].astype(str).str.strip().str.lower() == "yes").astype(int)
for c in ["Over18", "EmployeeCount", "StandardHours"]:
    if c in df.columns:
        df.drop(columns=[c], inplace=True)

df_no_label = df.drop(columns=["Attrition"]).copy() if "Attrition" in df.columns else df.copy()

st.sidebar.header("2) ÙÛŒÙ„ØªØ±Ù‡Ø§")
def get_opts(col, fallback):
    return sorted(df[col].dropna().astype(str).unique().tolist()) if col in df.columns else fallback

department = st.sidebar.multiselect("Department", get_opts("Department", []))
gender     = st.sidebar.multiselect("Gender", get_opts("Gender", []))
overtime   = st.sidebar.multiselect("OverTime", get_opts("OverTime", []))
age_range  = st.sidebar.slider("Age range", 18, int(df.get("Age", pd.Series([60])).max()), (18, 60))
inc_min = int(df.get("MonthlyIncome", pd.Series([500])).min()) if "MonthlyIncome" in df else 500
inc_max = int(df.get("MonthlyIncome", pd.Series([30000])).max()) if "MonthlyIncome" in df else 30000
inc_range  = st.sidebar.slider("MonthlyIncome range", inc_min, inc_max, (1009, 19999), step=100)

mask = pd.Series(True, index=df.index)
if department: mask &= df["Department"].astype(str).isin(department)
if gender:     mask &= df["Gender"].astype(str).isin(gender)
if overtime:   mask &= df["OverTime"].astype(str).isin(overtime)
if "Age" in df: mask &= df["Age"].between(*age_range, inclusive="both")
if "MonthlyIncome" in df: mask &= df["MonthlyIncome"].between(*inc_range, inclusive="both")

df_f = df[mask].copy()
st.sidebar.markdown(f"**Rows after filter:** {len(df_f):,}")

# ======= NAV =======
page = st.radio(
    " ",
    ("Ø®Ù„Ø§ØµÙ‡", "EDA", "Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…", "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ø§Ø±Ù…Ù†Ø¯ Ø¬Ø¯ÛŒØ¯", "Ø§ÙØ±Ø§Ø¯ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø±ÛŒØ³Ú©", "chat GPT", "Q&A", "What-If", "Cohorts"),
    horizontal=True, label_visibility="collapsed"
)

# ===================== Page 1: Overview =====================
if page == "Ø®Ù„Ø§ØµÙ‡":
    # --- KPI Cards (Status bar) ---
    k1, k2, k3, k4 = st.columns(4)
    with k1:
        st.metric("ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ú©Ù†Ø§Ù†", f"{len(df_f):,}")
    with k2:
        if "MonthlyIncome" in df_f.columns:
            st.metric("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ù‚ÙˆÙ‚ Ù…Ø§Ù‡Ø§Ù†Ù‡", f"{df_f['MonthlyIncome'].mean():,.0f}")
    with k3:
        if "_Attrition" in df_f.columns:
            st.metric("Attrition rate", f"{df_f['_Attrition'].mean():.1%}")
    with k4:
        if "OverTime" in df_f.columns:
            ot_yes = (df_f["OverTime"].astype(str) == "Yes").mean()
            st.metric("Ø¯Ø±ØµØ¯ Ø§ÙØ±Ø§Ø¯ÛŒ Ú©Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø§Ø± Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø±Ù†Ø¯", f"{ot_yes:.1%}")

    st.markdown("---")

    # --- Cross-filter (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) + Ø¯ÛŒØªØ§ÛŒ ØµÙØ­Ù‡ ---
    df_cf = df_f.copy()
    if "Department" in df_cf.columns:
        sel_dept = st.selectbox(
            "Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ Department",
            ["(Ù‡Ù…Ù‡)"] + get_opts("Department", [])
        )
        if sel_dept != "(Ù‡Ù…Ù‡)":
            df_cf = df_cf[df_cf["Department"].astype(str) == sel_dept]

    # --- Stacked Bar: Attrition by Department + Ø¯ÛŒØªØ§Ù„ÛŒØ¨Ù„ Ù†Ø±Ø® Ø±ÙˆÛŒ Ø³ØªÙˆÙ† Ù‚Ø±Ù…Ø² ---
    if {"Department", "Attrition"}.issubset(df_cf.columns):
        g = (
            df_cf.assign(Attrition=df_cf["Attrition"].astype(str))
                 .groupby(["Department", "Attrition"])
                 .size().reset_index(name="count")
        )
        # Ù…Ø¬Ù…ÙˆØ¹ Ù‡Ø± Ø¯Ù¾Ø§Ø±ØªÙ…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø±Ø®
        totals = g.groupby("Department")["count"].sum().reset_index(name="total")
        g = g.merge(totals, on="Department")
        g["rate"] = g["count"] / g["total"] * 100

        fig_dep = px.bar(
            g, x="Department", y="count", color="Attrition", barmode="stack",
            color_discrete_map={"Yes": "#E74C3C", "No": "#1f77b4"},
            category_orders={"Attrition": ["No", "Yes"]},  # Ù‚Ø±Ù…Ø² Ø±ÙˆÛŒÙ Ø³ØªÙˆÙ† Ù‚Ø±Ø§Ø± Ø¨Ú¯ÛŒØ±Ø¯
            title="Ù†Ø±Ø® Ø®Ø±ÙˆØ¬ Ù‡Ø± Ø¯Ù¾Ø§Ø±ØªÙ…Ø§Ù†",
            hover_data={"count":":,", "Department":True, "Attrition":True, "rate":":.1f"}
        )

        # Ø¯ÛŒØªØ§Ù„ÛŒØ¨Ù„Ù Ù†Ø±Ø® Ø®Ø±ÙˆØ¬ Ø±ÙˆÛŒ Ø¨Ø§Ù„Ø§ÛŒ Ø³ØªÙˆÙ† Ù‚Ø±Ù…Ø² (Yes)
        # Ú†ÙˆÙ† Ø§Ø³ØªÚ© Ø§Ø³ØªØŒ y Ø±Ø§ Ø±ÙˆÛŒ total Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ… ØªØ§ Ø¨Ø§Ù„Ø§ÛŒ Ú©Ù„ Ø³ØªÙˆÙ† Ø¨ÛŒØ§ÛŒØ¯
        for dep, grp in g[g["Attrition"] == "Yes"].groupby("Department"):
            total_val = float(grp["total"].iloc[0])
            rate_val  = float(grp["rate"].iloc[0])
            fig_dep.add_annotation(
                x=dep, y=total_val + 3,  # Ú©Ù…ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø³Ù‚Ù Ø³ØªÙˆÙ†
                text=f"{rate_val:.1f}%",
                showarrow=False,
                font=dict(color="white", size=12, family="Segoe UI"),
                align="center"
            )

        st.plotly_chart(fig_dep, use_container_width=True)

    # --- Pie: Overall Attrition Share ---
    if "Attrition" in df_cf.columns:
        pie_df = df_cf["Attrition"].astype(str).value_counts().reset_index()
        pie_df.columns = ["Attrition", "count"]
        fig_pie = px.pie(
            pie_df, names="Attrition", values="count",
            color="Attrition",
            color_discrete_map={"Yes": "#E74C3C", "No": "#1f77b4"},
            title="Ø³Ù‡Ù… Ø§Ø² ØªØ±Ú© Ú©Ø§Ø± Ø³Ø§Ø²Ù…Ø§Ù†", hole=0.35
        )
        st.plotly_chart(fig_pie, use_container_width=True)


# ===================== Page 2: EDA =====================
elif page == "EDA":
    st.subheader("ğŸ” EDA")

    # ----------------- 1) Interactive Correlation Heatmap (Plotly) -----------------
    num_cols = df_f.select_dtypes(include=[np.number]).columns.tolist()
    if num_cols:
        corr = df_f[num_cols].corr(numeric_only=True)
        fig_hm = go.Figure(
            data=go.Heatmap(
                z=corr.values, x=corr.columns, y=corr.index,
                colorscale="RdBu", zmin=-1, zmax=1,
                hovertemplate="x=%{x}<br>y=%{y}<br>corr=%{z:.2f}<extra></extra>"
            )
        )
        fig_hm.update_layout(
            title="Correlation Heatmap (interactive)",
            height=520, margin=dict(t=50, l=60, r=20, b=40)
        )
        st.plotly_chart(fig_hm, use_container_width=True)

    st.markdown("---")

    # ----------------- 2) Age Histogram with adjustable bins -----------------
    if {"Age", "Attrition"}.issubset(df_f.columns):
        bins = st.slider("ØªØ¹Ø¯Ø§Ø¯ bins Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ø³Ù†", 5, 60, 20, 1, key="eda_bins_age")
        fig_hist = px.histogram(
            df_f, x="Age", color="Attrition", nbins=bins,
            barmode="overlay", opacity=0.6,
            color_discrete_map=ATTRITION_COLORS,
            title="Age Distribution by Attrition"
        )
        st.plotly_chart(fig_hist, use_container_width=True)

    st.markdown("---")

    # ----------------- 3) 3D Scatter + Selectable Correlation -----------------
    # Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ø±ÙˆÛŒ df_f Ø§Ø³Øª (Ù†Ù‡ dfp) ØªØ§ Ø§Ø±ÙˆØ±ÛŒ Ø§Ø² Ù†Ø¨ÙˆØ¯Ù† Ù…ØªØºÛŒØ± Ø±Ø® Ù†Ø¯Ù‡Ø¯.
    num_cols_all = df_f.select_dtypes(include=[np.number]).columns.tolist()
    has_needed = {"Age", "MonthlyIncome", "DistanceFromHome"}.issubset(df_f.columns)

    if has_needed and len(num_cols_all) >= 3:
        st.markdown("### ğŸ” Ø§Ú©ØªØ´Ø§Ù Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ + Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ")

        c_left, c_mid, c_right = st.columns([1.2, 1.2, 1])

        with c_left:
            x3d = st.selectbox(
                "X (Ø¹Ø¯Ø¯ÛŒ)", options=num_cols_all,
                index=(num_cols_all.index("Age") if "Age" in num_cols_all else 0),
                key="eda_x3d"
            )
            y3d = st.selectbox(
                "Y (Ø¹Ø¯Ø¯ÛŒ)", options=num_cols_all,
                index=(num_cols_all.index("MonthlyIncome") if "MonthlyIncome" in num_cols_all else min(1, len(num_cols_all)-1)),
                key="eda_y3d"
            )
            z3d = st.selectbox(
                "Z (Ø¹Ø¯Ø¯ÛŒ)", options=num_cols_all,
                index=(num_cols_all.index("DistanceFromHome") if "DistanceFromHome" in num_cols_all else min(2, len(num_cols_all)-1)),
                key="eda_z3d"
            )

        with c_mid:
            marker_size = st.slider("Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÛŒ Ù†Ù‚Ø§Ø· (3D)", 2, 10, 4, 1, key="eda_marker3d")
            opacity3d   = st.slider("Ø´ÙØ§ÙÛŒØª Ù†Ù‚Ø§Ø·", 0.2, 1.0, 0.7, 0.05, key="eda_opacity3d")
            lo = 200 if len(df_f) >= 200 else max(50, len(df_f)//5 or 1)
            hi = min(2000, max(1, len(df_f)))
            default_n = min(800, hi)
            sample_n = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ (Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª)", lo, hi, default_n, 50, key="eda_sample3d")

        with c_right:
            corr_x = st.selectbox(
                "Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ: Ù…ØªØºÛŒØ± Ø§ÙˆÙ„", options=num_cols_all,
                index=(num_cols_all.index("Age") if "Age" in num_cols_all else 0),
                key="eda_corrx"
            )
            corr_y = st.selectbox(
                "Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ: Ù…ØªØºÛŒØ± Ø¯ÙˆÙ…", options=num_cols_all,
                index=(num_cols_all.index("MonthlyIncome") if "MonthlyIncome" in num_cols_all else min(1, len(num_cols_all)-1)),
                key="eda_corry"
            )
            corr_method = st.radio("Ø±ÙˆØ´ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ", ["Pearson", "Spearman"], horizontal=True, key="eda_corrm")

        # Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ (Ø¨Ø±Ø§ÛŒ Ø±Ù†Ø¯Ø± Ù†Ø±Ù… 3D)
        df3 = df_f.sample(sample_n, random_state=RANDOM_STATE) if len(df_f) > sample_n else df_f.copy()

        # 3D Scatter (Ø­Ø¨Ø§Ø¨â€ŒÙ‡Ø§ Ú©ÙˆÚ†Ú©ØªØ± Ùˆ Ø®ÙˆØ§Ù†Ø§ØªØ±)
        fig3d = px.scatter_3d(
            df3, x=x3d, y=y3d, z=z3d,
            color=("Attrition" if "Attrition" in df3.columns else None),
            color_discrete_map=ATTRITION_COLORS,
            opacity=opacity3d,
            hover_data={x3d:":,.0f", y3d:":,.0f", z3d:":,.0f"},
            title=f"3D Scatter: {x3d} â€¢ {y3d} â€¢ {z3d}"
        )
        fig3d.update_traces(marker=dict(size=marker_size))
        fig3d.update_layout(scene=dict(
            xaxis_title=x3d, yaxis_title=y3d, zaxis_title=z3d,
            camera=dict(eye=dict(x=1.6, y=1.6, z=0.9))
        ))
        st.plotly_chart(fig3d, use_container_width=True)

        # Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒÙ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ + Ù†Ù…Ø§ÛŒØ´ Ø¨ØµØ±ÛŒ Ú©Ù…Ú©ÛŒ
        s1 = pd.to_numeric(df_f[corr_x], errors="coerce")
        s2 = pd.to_numeric(df_f[corr_y], errors="coerce")
        clean = pd.DataFrame({corr_x: s1, corr_y: s2}).dropna()

        if len(clean) >= 3:
            corr_val = clean[corr_x].corr(clean[corr_y], method=("pearson" if corr_method == "Pearson" else "spearman"))
            k1, k2 = st.columns(2)
            with k1:
                st.metric(f"Ø¶Ø±ÛŒØ¨ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ ({corr_method})", f"{corr_val:.3f}")
            with k2:
                st.caption(f"Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±: {len(clean):,}")

            view_mode = st.radio(
                "Ù†Ù…Ø§ÛŒØ´ Ø¯ÙˆØ¨Ø¹Ø¯ÛŒÙ Ú©Ù…Ú©â€ŒØ¨ØµØ±ÛŒ", ["Scatter", "Density (Heatmap)"],
                horizontal=True, key="eda_corr_view"
            )
            if view_mode == "Scatter":
                fig2d = px.scatter(
                    clean, x=corr_x, y=corr_y,
                    color=(df_f.loc[clean.index, "Attrition"].astype(str) if "Attrition" in df_f.columns else None),
                    color_discrete_map=ATTRITION_COLORS,
                    opacity=0.7,
                    hover_data={corr_x:":,.0f", corr_y:":,.0f"},
                    title=f"Scatter: {corr_x} vs {corr_y}"
                )
                fig2d.update_traces(marker=dict(size=6, line=dict(width=0)))
            else:
                fig2d = px.density_heatmap(
                    clean, x=corr_x, y=corr_y,
                    nbinsx=30, nbinsy=30, color_continuous_scale="Viridis",
                    title=f"Density Heatmap: {corr_x} vs {corr_y}"
                )
            st.plotly_chart(fig2d, use_container_width=True)
        else:
            st.info("Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ú©Ø§ÙÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")

    st.markdown("---")

    # ----------------- 4) K-Means + Attrition Filter + Cluster Labels -----------------
    st.subheader("ğŸ§© Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (K-Means) + ÙÛŒÙ„ØªØ± Attrition")
    attr_filter = st.radio(
        "ÙˆØ¶Ø¹ÛŒØª Attrition Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ",
        ("Ù‡Ø± Ø¯Ùˆ", "ÙÙ‚Ø· ØªØ±Ú© Ú©Ø±Ø¯Ù‡â€ŒÙ‡Ø§ (Yes)", "ÙÙ‚Ø· Ù…Ø§Ù†Ø¯Ù‡â€ŒÙ‡Ø§ (No)"),
        horizontal=True, key="eda_attr_filter"
    )
    base_df = df_f.copy()
    if "Attrition" in base_df.columns:
        if attr_filter == "ÙÙ‚Ø· ØªØ±Ú© Ú©Ø±Ø¯Ù‡â€ŒÙ‡Ø§ (Yes)":
            base_df = base_df[base_df["Attrition"].astype(str) == "Yes"]
        elif attr_filter == "ÙÙ‚Ø· Ù…Ø§Ù†Ø¯Ù‡â€ŒÙ‡Ø§ (No)":
            base_df = base_df[base_df["Attrition"].astype(str) == "No"]

    num_cols_eda = base_df.select_dtypes(include=[np.number]).columns.tolist()
    with st.expander("Ø±Ø§Ù‡Ù†Ù…Ø§", expanded=False):
        st.write("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ØŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ KMeans Ø§Ø¬Ø±Ø§ Ùˆ Ø¨Ø§ PCA Ø¯Ùˆâ€ŒØ¨Ø¹Ø¯ÛŒ (Ø±Ù†Ú¯=Ø®ÙˆØ´Ù‡ØŒ Ù†Ù…Ø§Ø¯=Attrition) Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

    choose_cols = st.multiselect(
        "Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ",
        options=num_cols_eda,
        default=[c for c in ["Age", "MonthlyIncome", "DistanceFromHome", "YearsAtCompany"] if c in num_cols_eda],
        key="eda_km_cols"
    )
    k = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ (k)", 2, 8, 3, 1, key="eda_km_k")

    # Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø³Ø§Ø¯Ù‡â€ŒÛŒ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
    def _label_cluster(row):
        parts = []
        if "MonthlyIncome" in row and not pd.isna(row.get("MonthlyIncome_q3")) and row["MonthlyIncome"] >= row["MonthlyIncome_q3"]:
            parts.append("High Income")
        elif "MonthlyIncome" in row and not pd.isna(row.get("MonthlyIncome_q1")) and row["MonthlyIncome"] <= row["MonthlyIncome_q1"]:
            parts.append("Low Income")
        if "YearsAtCompany" in row and row["YearsAtCompany"] <= 2:
            parts.append("Newcomers")
        if "Age" in row and row["Age"] <= 30:
            parts.append("Young")
        if "DistanceFromHome" in row and row["DistanceFromHome"] >= 15:
            parts.append("Far Home")
        return ", ".join(parts) if parts else "General"

    if st.button("ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", key="eda_run_kmeans"):
        if len(choose_cols) < 2:
            st.warning("Ø­Ø¯Ø§Ù‚Ù„ Û² Ø³ØªÙˆÙ† Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†.")
        else:
            # ÙÙ‚Ø· Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ
            Xc = base_df[choose_cols].dropna().copy()
            if Xc.empty:
                st.warning("Ù¾Ø³ Ø§Ø² ÙÛŒÙ„ØªØ± Attrition ÛŒØ§ Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯Ù‡ Ø§Ø³Øª.")
            else:
                # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ùˆ KMeans
                from sklearn.preprocessing import StandardScaler
                Xs = StandardScaler().fit_transform(Xc)
                km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)
                labels = km.fit_predict(Xs)

                # Ú©ÛŒÙÛŒØª
                sil = silhouette_score(Xs, labels)
                st.success(f"Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Silhouette Score = **{sil:.3f}**")
                st.caption(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒØ´Ø¯Ù‡: {len(Xc):,}")

                # Ù¾Ø±ÙˆÙØ§ÛŒÙ„
                prof = Xc.assign(cluster=labels).groupby("cluster").agg(["mean", "median", "count"])
                st.write("**Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§:**")
                st.dataframe(prof, use_container_width=True)

                # Ø¨Ø±Ú†Ø³Ø¨ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø§ ØµØ¯Ú©â€ŒÙ‡Ø§
                q = base_df[choose_cols].quantile([.25, .75])
                q1, q3 = q.iloc[0], q.iloc[1]
                centers = Xc.assign(cluster=labels).groupby("cluster").mean()
                for c in centers.columns:
                    centers[c + "_q1"] = q1.get(c, np.nan)
                    centers[c + "_q3"] = q3.get(c, np.nan)
                centers["label"] = centers.apply(_label_cluster, axis=1)
                st.write("**Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§:**")
                st.dataframe(centers[["label"]], use_container_width=True)

                # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±: Ø±Ù†Ú¯=Ø®ÙˆØ´Ù‡ØŒ Ù†Ù…Ø§Ø¯=Attrition
                if "Attrition" in base_df.columns:
                    attr_sym = base_df.loc[Xc.index, "Attrition"].astype(str)
                else:
                    attr_sym = pd.Series(["Unknown"] * len(Xc), index=Xc.index)

                pts = PCA(n_components=2, random_state=RANDOM_STATE).fit_transform(Xs)
                plot_df = pd.DataFrame({
                    "pc1": pts[:, 0], "pc2": pts[:, 1],
                    "cluster": labels.astype(str),
                    "Attrition": attr_sym.values
                })
                fig = px.scatter(
                    plot_df, x="pc1", y="pc2", color="cluster", symbol="Attrition",
                    symbol_map={"Yes": "x", "No": "circle"},
                    title="KMeans clusters (PCA 2D) â€” Ù†Ù…Ø§Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Attrition"
                )
                fig.update_traces(marker=dict(size=6, opacity=0.85))
                show_fig(fig, height=420)

                # Ø¬Ø¯ÙˆÙ„ Ø´Ù…Ø§Ø±Ø´ Ø§Ø¹Ø¶Ø§ÛŒ Ù‡Ø± Ø®ÙˆØ´Ù‡ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Attrition
                if "Attrition" in base_df.columns:
                    cnt = plot_df.groupby(["cluster", "Attrition"]).size().reset_index(name="count")
                    st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø§ÙØ±Ø§Ø¯ Ù‡Ø± Ø®ÙˆØ´Ù‡ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Attrition:**")
                    st.dataframe(cnt, use_container_width=True)

# ===================== Page 3: Model Evaluation =====================
elif page == "Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…":
    st.subheader("ğŸ“ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„")
    work_df = df_no_label.copy()
    target = "_Attrition"
    y = work_df[target].values
    X = work_df.drop(columns=[target])

    with st.spinner("Ø¯Ø±Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ù‡Ø§"):
        res_df, best_model, splits, pr_curves = fit_and_eval_all(X, y)
        X_tr, X_te, y_tr, y_te = splits

        st.success("Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
    st.write("**Ù†ØªØ§ÛŒØ¬ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ (Ù…Ø±ØªØ¨ Ø¨Ø± Ø§Ø³Ø§Ø³ F1):**")

    # ğŸ“Š Ù…Ø§ØªØ±ÛŒØ³ Ø´Ø±Ø·ÛŒ Ø¨Ù‡â€ŒØ¬Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± PR
    st.subheader("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ (Ù…Ø§ØªØ±ÛŒØ³ Ø¨Ø§ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø±Ø·ÛŒ)")

    # ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø²ÛŒ Ø±Ø§ Ø¨Ø±Ø¯Ø§Ø±ÛŒÙ…
    score_cols = ["Accuracy", "Precision", "Recall", "F1", "PR_AUC"]
    mat = (
        res_df
        .set_index("model")[score_cols]
        .astype(float)
        .round(3)
    )

    # Ù‡Ø§ÛŒÙ„Ø§ÛŒØª Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ù‡Ø± Ø³ØªÙˆÙ†
    def highlight_best(col):
        is_best = col == col.max()
        return ["font-weight:700; border:1px solid #555;" if v else "" for v in is_best]

    # Ø§Ø³ØªØ§ÛŒÙ„â€ŒØ¯Ù‡ÛŒ: Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø±Ù†Ú¯ + Ù‡Ø§ÛŒÙ„Ø§ÛŒØª
    sty = (
        mat.style
        .background_gradient(cmap="RdYlGn", axis=0)   # Ø³Ø¨Ø²=Ø®ÙˆØ¨ØŒ Ù‚Ø±Ù…Ø²=Ø¶Ø¹ÛŒÙ
        .apply(highlight_best, axis=0)                # Ø¨Ù‡ØªØ±ÛŒÙ† Ù‡Ø± Ø³ØªÙˆÙ†
        .format("{:.3f}")
        .set_caption("Higher is better (Green â†’ Red)")
    )

    st.dataframe(sty, use_container_width=True)


    # --- Radar chart: compare models on metrics ---
    melt = res_df[["model","Accuracy","Precision","Recall","F1","PR_AUC"]].melt(
        id_vars="model", var_name="metric", value_name="val"
    )
    fig_radar = px.line_polar(melt, r="val", theta="metric", color="model", line_close=True,
                              title="Radar: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§")
    fig_radar.update_traces(fill='toself', opacity=0.6)
    st.plotly_chart(fig_radar, use_container_width=True)

    # --- Confusion Matrix as heatmap (green=correct, red=error) ---
    y_pred = best_model.predict(X_te)
    cm = confusion_matrix(y_te, y_pred)
    fig_cm = go.Figure(data=go.Heatmap(
        z=cm,
        x=["Pred Stay(0)","Pred Leave(1)"], y=["True Stay(0)","True Leave(1)"],
        colorscale=[ [0,"#0b6623"], [0.5,"#e8e8e8"], [1,"#b71c1c"] ],
        text=cm, texttemplate="%{text}",
        hovertemplate="x=%{x}<br>y=%{y}<br>count=%{z}<extra></extra>"
    ))
    fig_cm.update_layout(title="Confusion Matrix (Best)", height=420)
    st.plotly_chart(fig_cm, use_container_width=True)

    st.subheader("Feature Importance (Permutation)")
    from sklearn.inspection import permutation_importance

    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ X_all Ù…Ø·Ø§Ø¨Ù‚ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
    X_all = df_no_label.copy()
    y_all = X_all["_Attrition"].values
    X_all = X_all.drop(columns=["_Attrition"])
    prep = best_model.named_steps["prep"]
    cols = list(prep.feature_names_in_)
    for c in cols:
        if c not in X_all: X_all[c] = np.nan
    X_all = X_all[cols]

    r = permutation_importance(best_model, X_all, y_all,
                               n_repeats=8, random_state=RANDOM_STATE, scoring="f1")
    imp = pd.DataFrame({"feature": cols, "importance": r.importances_mean}) \
            .sort_values("importance", ascending=False).head(20)
    fig_imp = px.bar(imp, x="importance", y="feature", orientation="h",
                     title="Top Features (Permutation)")
    st.plotly_chart(fig_imp, use_container_width=True)

# ===================== Page 4: New Prediction =====================
elif page == "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ø§Ø±Ù…Ù†Ø¯ Ø¬Ø¯ÛŒØ¯":
    st.subheader("ğŸ¤– Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„")
    model = None
    if os.path.exists(MODEL_PATH):
        try:
            model = load(MODEL_PATH)
            st.success(f"Ù…Ø¯Ù„ Ø®Ø§Ø±Ø¬ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {MODEL_PATH}")
        except Exception as e:
            st.warning(f"Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø®Ø§Ø±Ø¬ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯:\n{e}")
    if model is None and os.path.exists("best_model.joblib"):
        try:
            model = load("best_model.joblib")
            st.success("best_model.joblib (Ø¯Ø§Ø®Ù„ Ù¾ÙˆØ´Ù‡) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        except Exception as e:
            st.warning(f"Ù„ÙˆØ¯ best_model.joblib Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
    if model is None:
        st.error("Ù…Ø¯Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± ØµÙØ­Ù‡ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒØŒ Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†.")
        st.stop()

    st.markdown("**ÙØ±Ù… ÙˆØ±ÙˆØ¯ÛŒ**")
    c1, c2, c3 = st.columns(3)
    Age = c1.number_input("Age", 18, 70, 30)
    MonthlyIncome = c2.number_input("MonthlyIncome", 500, 30000, 5000, step=100)
    DistanceFromHome = c3.number_input("DistanceFromHome", 0, 60, 10)
    YearsAtCompany = c1.number_input("YearsAtCompany", 0, 40, 3)
    Education = c2.selectbox("Education (1-5)", [1,2,3,4,5], index=2)

    def opts(col, fallback):
        return sorted(df[col].dropna().astype(str).unique().tolist()) if col in df.columns else fallback
    Gender = c3.selectbox("Gender", opts("Gender", ["Male","Female"]))
    Department = c1.selectbox("Department", opts("Department", ["Sales","Research & Development","Human Resources"]))
    JobRole = c2.selectbox("JobRole", opts("JobRole", ["Sales Executive"]))
    OverTime = c3.selectbox("OverTime", opts("OverTime", ["Yes","No"]))
    MaritalStatus = c1.selectbox("MaritalStatus", opts("MaritalStatus", ["Single","Married","Divorced"]))
    Threshold = c2.slider("Decision Threshold (Leave)", 0.05, 0.8, 0.3, 0.01)

    if st.button("ğŸ”® Predict"):
     sample = {
        "Age": Age,
        "MonthlyIncome": MonthlyIncome,
        "DistanceFromHome": DistanceFromHome,
        "YearsAtCompany": YearsAtCompany,
        "Education": Education,
        "Gender": Gender,
        "Department": Department,
        "JobRole": JobRole,
        "OverTime": OverTime,
        "MaritalStatus": MaritalStatus,
    }

    try:
        label, prob = predict_with_pipeline(model, sample, threshold=Threshold)

        # Ù…ØªÙ† Ù†ØªÛŒØ¬Ù‡
        st.markdown(
            f"**Ù†ØªÛŒØ¬Ù‡:** `{label}` | **Prob(Leave):** `{prob:.1%}` | **Threshold:** `{Threshold:.2f}`"
        )

        # --- Gauge Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø§Ø­ØªÙ…Ø§Ù„ ---
        fig_g = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=prob * 100,
            number={'suffix': " %"},
            delta={'reference': Threshold * 100},
            gauge={
                'axis': {'range': [0, 100]},
                'bar': {'color': "#E74C3C" if prob >= Threshold else "#1f77b4"},
                'steps': [
                    {'range': [0, 30], 'color': "#2b4c7e"},
                    {'range': [30, 60], 'color': "#ffa94d"},
                    {'range': [60, 100], 'color': "#ff6b6b"},
                ],
                'threshold': {
                    'line': {'color': "white", 'width': 3},
                    'thickness': 0.75,
                    'value': Threshold * 100,
                }
            }
        ))
        fig_g.update_layout(title="Gauge: Ø§Ø­ØªÙ…Ø§Ù„ Leave")
        st.plotly_chart(fig_g, use_container_width=True)

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {e}")


# ===================== Page 5: Q&A =====================
elif page == "Q&A":
    st.subheader("ğŸ’¬ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ù‡ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ")

    # 1) Ú©Ø¯Ø§Ù… Ø¯Ù¾Ø§Ø±ØªÙ…Ø§Ù† Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù†Ø±Ø® ØªØ±Ú© Ú©Ø§Ø± Ø±Ø§ Ø¯Ø§Ø±Ø¯ Ùˆ Ú†Ø±Ø§ØŸ
    st.markdown("**1) Ú©Ø¯Ø§Ù… Ø¯Ù¾Ø§Ø±ØªÙ…Ø§Ù† Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù†Ø±Ø® ØªØ±Ú© Ú©Ø§Ø± Ø±Ø§ Ø¯Ø§Ø±Ø¯ Ùˆ Ú†Ø±Ø§ØŸ**")
    if "Department" in df_f.columns:
        rate_by_dept = df_f.groupby("Department")["_Attrition"].mean().sort_values(ascending=False)
        st.write(rate_by_dept.to_frame("AttritionRate"))
        top_dept = rate_by_dept.index[0]
        st.info(f"The highest rate of abandonment is related to: **{top_dept}** at a rate of**{rate_by_dept.iloc[0]:.1%}**")
        hints = []
        if {"MonthlyIncome","Department"}.issubset(df_f.columns):
            mean_income = df_f.groupby("Department")["MonthlyIncome"].mean().sort_values()
            if top_dept in mean_income.index[:1]:
                hints.append("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ù‚ÙˆÙ‚ Ø¯Ø± Ø§ÛŒÙ† Ø¯Ù¾Ø§Ø±ØªÙ…Ø§Ù† Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ø¨Ù‚ÛŒÙ‡ Ø§Ø³Øª.")
        if {"OverTime","Department"}.issubset(df_f.columns):
            ot_rate = df_f[df_f["OverTime"]=="Yes"].groupby("Department")["_Attrition"].mean().sort_values(ascending=False)
            if top_dept in ot_rate.index[:1]:
                hints.append("The Attrition rate is higher among overtime here.")
        if hints:
            st.write("Possible reasons:", "ØŒ ".join(hints))
    else:
        st.warning("The Department column is not available.")

    st.markdown("---")

    # Ù†Ù…ÙˆØ¯Ø§Ø± ØªÚ©Ù…ÛŒÙ„ÛŒ OverTime vs Attrition
    if "OverTime" in df_f.columns:
        piv = df_f.groupby(["OverTime","Attrition"]).size().reset_index(name="count")
        fig = px.bar(piv, x="OverTime", y="count", color="Attrition",
                     color_discrete_map=ATTRITION_COLORS, barmode="group",
                     template="plotly_dark", title="Count by OverTime & Attrition")
        fig.update_traces(hovertemplate="OverTime=%{x}<br>Attrition=%{legendgroup}<br>Count=%{y}<extra></extra>")
        show_fig(fig, height=380)

    # 2) Ø¢ÛŒØ§ OverTime Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ Ø¨Ø§ ØªØ±Ú© Ú©Ø§Ø± Ø¯Ø§Ø±Ø¯ØŸ
    st.markdown("**2) Ø¢ÛŒØ§ Ø§Ø¶Ø§ÙÙ‡â€ŒÚ©Ø§Ø±ÛŒ Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ Ø¨Ø§ ØªØ±Ú© Ú©Ø§Ø± Ø¯Ø§Ø±Ø¯ØŸ**")
    if "OverTime" in df_f.columns:
        base = df_f["_Attrition"].mean()
        ot_yes = df_f.loc[df_f["OverTime"]=="Yes","_Attrition"].mean()
        ot_no  = df_f.loc[df_f["OverTime"]=="No","_Attrition"].mean() if "No" in df_f["OverTime"].unique() else np.nan
        st.write(pd.DataFrame({"Overall":[base], "OT=Yes":[ot_yes], "OT=No":[ot_no]}).T.rename(columns={0:"AttritionRate"}))
        if ot_yes > base:
            st.info("Yes-the Attrition rate for overtime=Yes is higher than the average.")
        else:
            st.info("Strong evidence for overtime's direct relationship with Attrition was not seen (in current filtered data).")
    else:
        st.warning("Overtime column is not available.")

    st.markdown("---")

    # 3) Ú©Ø§Ø±Ú©Ù†Ø§Ù† Ø¨Ø§ Ú†Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø®Ø±ÙˆØ¬ Ù‡Ø³ØªÙ†Ø¯ØŸ
    st.markdown("**3) Ú©Ø§Ø±Ú©Ù†Ø§Ù†ÛŒ Ø¨Ø§ Ú†Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ (Ø³Ù†ØŒ Ø¯Ø±Ø¢Ù…Ø¯ØŒ Ø³Ø§Ø¨Ù‚Ù‡) Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø®Ø±ÙˆØ¬ Ù‡Ø³ØªÙ†Ø¯ØŸ**")
    hints = []
    if "Age" in df_f:
        young = df_f[df_f["Age"]<=df_f["Age"].quantile(0.25)]["_Attrition"].mean()
        old   = df_f[df_f["Age"]>=df_f["Age"].quantile(0.75)]["_Attrition"].mean()
        hints.append(f"Lower age group (Quartile1) rate of Attrition â‰ˆ {young:.1%}ØŒ Elderly group (Quartile4) â‰ˆ {old:.1%}.")
    if "MonthlyIncome" in df_f:
        low_inc = df_f[df_f["MonthlyIncome"]<=df_f["MonthlyIncome"].quantile(0.25)]["_Attrition"].mean()
        high_inc= df_f[df_f["MonthlyIncome"]>=df_f["MonthlyIncome"].quantile(0.75)]["_Attrition"].mean()
        hints.append(f"Wages lower than Q1 Attrition rateâ‰ˆ {low_inc:.1%}ØŒ salary above Q3 â‰ˆ {high_inc:.1%}.")
    if "YearsAtCompany" in df_f:
        low_ten = df_f[df_f["YearsAtCompany"]<=2]["_Attrition"].mean()
        hints.append(f" The tenure rate â‰¤2 years is often riskier â‰ˆ {low_ten:.1%}).")
    if hints:
        st.write("- " + "\n- ".join(hints))

    st.markdown("---")

    st.markdown("**4) Ø±ÛŒÚ©Ø§Ù„ Ù…Ø¯Ù„ Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ**")
    if "best_model_recall" in st.session_state:
        st.success(f"Ø±ÛŒÚ©Ø§Ù„ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ (Ø§Ø² ØµÙØ­Ù‡ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ): **{st.session_state['best_model_recall']:.3f}**")
    else:
        st.info("First, go to the model evaluation page and run the models to record the Recall.")

    st.markdown("---")

    st.markdown("**5) Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ù‡Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø´Øª Ú©Ø§Ø±Ú©Ù†Ø§Ù†**")
    st.write("""- Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø¶Ø§ÙÙ‡â€ŒÚ©Ø§Ø±ÛŒ Ùˆ ØªÙˆØ§Ø²Ù† Ø²Ù†Ø¯Ú¯ÛŒ-Ú©Ø§Ø±
- Ø¨Ø§Ø²Ù†Ú¯Ø±ÛŒ Ø­Ù‚ÙˆÙ‚/Ù…Ø²Ø§ÛŒØ§ Ø¨Ø±Ø§ÛŒ Ø²ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§
- Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ø¨ÙˆØ±Ø¯ÛŒÙ†Ú¯ Ùˆ Ù…Ù†ØªÙˆØ±ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ ØªØ§Ø²Ù‡â€ŒÙˆØ§Ø±Ø¯Ù‡Ø§
- Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ø´ØºÙ„ÛŒ/Ù…Ø­ÛŒØ·ÛŒ Ùˆ Ù…Ø³ÛŒØ± Ø±Ø´Ø¯
- ØªØ³Ù‡ÛŒÙ„Ø§Øª Ø±ÙØªâ€ŒÙˆØ¢Ù…Ø¯ ÛŒØ§ Ø¯ÙˆØ±Ú©Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ§Ø¯
""")

# ===================== Page 6: High-Risk Stayers =====================
elif page == "Ø§ÙØ±Ø§Ø¯ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø±ÛŒØ³Ú©":
    st.subheader("ğŸš¨ ÙÙ‡Ø±Ø³Øª Ú©Ø§Ø±Ú©Ù†Ø§Ù†Ù Ø¯Ø± Ø­Ø§Ù„ Ú©Ø§Ø± Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ø­ØªÙ…Ø§Ù„ Ø®Ø±ÙˆØ¬")

    # load model
    model = None
    if os.path.exists(MODEL_PATH):
        try: model = load(MODEL_PATH)
        except Exception as e: st.warning(f"Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø®Ø§Ø±Ø¬ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯:\n{e}")
    if model is None and os.path.exists("best_model.joblib"):
        try: model = load("best_model.joblib")
        except Exception as e: st.warning(f"Ù„ÙˆØ¯ best_model.joblib Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
    if model is None:
        st.error("Ù…Ø¯Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± ØµÙØ­Ù‡ Â«Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…Â» Ù…Ø¯Ù„ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†.")
        st.stop()

    if "_Attrition" not in df_f.columns:
        st.error("Ø³ØªÙˆÙ† _Attrition Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."); st.stop()

    still_here = df_f[df_f["_Attrition"] == 0].copy()
    if still_here.empty:
        st.info("Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ ÙØ¹Ù„ÛŒØŒ Ù…ÙˆØ±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Stay ÛŒØ§ÙØª Ù†Ø´Ø¯."); st.stop()

    prep = model.named_steps.get("prep", None)
    if prep is None or not hasattr(prep, "feature_names_in_"):
        st.error("Ù…Ø¯Ù„ Ø¨Ø§ÛŒØ¯ Pipeline Ø¨Ø§ Ú¯Ø§Ù… 'prep' Ø¨Ø§Ø´Ø¯."); st.stop()
    feature_cols = list(prep.feature_names_in_)

    X_batch_for_model = still_here.drop(columns=[c for c in ["EmployeeNumber","Attrition"] if c in still_here.columns])
    for c in feature_cols:
        if c not in X_batch_for_model.columns:
            X_batch_for_model[c] = np.nan
    X_batch_for_model = X_batch_for_model[feature_cols]

    try:
        risk_prob = model.predict_proba(X_batch_for_model)[:, 1]
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú¯Ø±ÙˆÙ‡ÛŒ: {e}"); st.stop()

    still_here["Risk(Leave)"] = risk_prob

    # risk factors (for heat-like styling)
    def inv_minmax(s): s=s.astype(float); return 1 - (s - s.min())/(s.max()-s.min()+1e-9)
    def minmax(s):    s=s.astype(float); return     (s - s.min())/(s.max()-s.min()+1e-9)

    if "OverTime" in still_here: still_here["rf_OverTime"] = (still_here["OverTime"].astype(str)=="Yes").astype(float)
    if "MonthlyIncome" in still_here: still_here["rf_LowIncome"] = inv_minmax(still_here["MonthlyIncome"])
    if "YearsAtCompany" in still_here:
        y = still_here["YearsAtCompany"].astype(float)
        still_here["rf_LowTenure"] = np.clip((5 - y) / 5.0, 0, 1)
    if "JobSatisfaction" in still_here:
        m = {1:1.0, 2:0.66, 3:0.33, 4:0.0}
        still_here["rf_JobSatLow"] = still_here["JobSatisfaction"].map(m).fillna(0.5)
    if "EnvironmentSatisfaction" in still_here:
        m2 = {1:1.0, 2:0.66, 3:0.33, 4:0.0}
        still_here["rf_EnvSatLow"] = still_here["EnvironmentSatisfaction"].map(m2).fillna(0.5)
    if "DistanceFromHome" in still_here:
        still_here["rf_FarHome"] = minmax(still_here["DistanceFromHome"])

    # Key Role heuristic
    key_mask = pd.Series(False, index=still_here.index)
    if "JobLevel" in still_here: key_mask |= (still_here["JobLevel"].fillna(1) >= 4)
    if "MonthlyIncome" in still_here:
        q3 = still_here["MonthlyIncome"].quantile(0.75)
        key_mask |= (still_here["MonthlyIncome"] >= q3)
    if "PerformanceRating" in still_here: key_mask |= (still_here["PerformanceRating"].fillna(3) >= 4)
    still_here.insert(1, "Key Role", np.where(key_mask, "Yes", "No"))

    show_cols = [c for c in ["EmployeeNumber","Key Role","Department","JobRole","Age","Gender",
                             "MonthlyIncome","YearsAtCompany","OverTime","JobSatisfaction",
                             "EnvironmentSatisfaction","DistanceFromHome","Risk(Leave)"] if c in still_here.columns]
    risk_cols = [c for c in still_here.columns if c.startswith("rf_")]

    top_k = st.slider("Ú†Ù†Ø¯ Ù†ÙØ±Ù Ø§ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŸ", 5, min(200, len(still_here)), 30, 5)
    out = still_here.sort_values("Risk(Leave)", ascending=False).head(top_k)[show_cols + risk_cols]

    import matplotlib
    reds = matplotlib.cm.get_cmap("Reds")
    sty = (out.style
           .format({"Risk(Leave)": "{:.1%}", "MonthlyIncome": "{:,.0f}"})
           .set_caption("High-Risk Stayers")
           .background_gradient(cmap=reds, subset=risk_cols))
    st.write("**ØªÙˆØ¶ÛŒØ­ Ø±Ù†Ú¯â€ŒÙ‡Ø§:** Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ rf_* Ø´Ø¯Øª Ø¹ÙˆØ§Ù…Ù„ÛŒ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ Ú©Ù‡ Ø±ÛŒØ³Ú© Ø±Ø§ Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ¨Ø±Ù†Ø¯ (Ù‚Ø±Ù…Ø² Ù¾Ø±Ø±Ù†Ú¯=Ø¨Ø¯ØªØ±).")
    st.dataframe(sty, use_container_width=True)

    csv = out.drop(columns=risk_cols).to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV", data=csv, file_name="high_risk_stayers.csv", mime="text/csv")

# ===================== Page 7: GPT Chatbot =====================
elif page == "chat GPT":
    from openai import OpenAI

    st.subheader("ğŸ¤– Ø¯Ø±Ù…ÙˆØ±Ø¯ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§Øª Ù‡Ø± Ø³ÙˆØ§Ù„ÛŒ Ø§Ø²Ù… Ø¯Ø§Ø±ÛŒ Ø¨Ù¾Ø±Ø³")

    with st.expander("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØªØµØ§Ù„", expanded=False):
        st.write("Ú©Ù„ÛŒØ¯ OpenAI Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù† (ÙÙ‚Ø· Ø¯Ø± Ù‡Ù…ÛŒÙ† Ø¬Ù„Ø³Ù‡ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯).")
        api_key = st.text_input("OPENAI_API_KEY", type="password", value=st.session_state.get("api_key",""))
        if st.checkbox("Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª Ø¯Ø± Session", value=True):
            if api_key: st.session_state["api_key"] = api_key

    api_key = st.session_state.get("api_key") or st.secrets["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"]
    if not api_key:
        st.warning("Ú©Ù„ÛŒØ¯ OpenAI Ø±Ø§ Ø¨Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ù…Ø­ÛŒØ· Ø³ÛŒØ³ØªÙ… ØªÙ†Ø¸ÛŒÙ… Ú©Ù†.")
        st.stop()
    client = OpenAI(api_key=api_key)

    if "chat_history_fc" not in st.session_state:
        st.session_state.chat_history_fc = []

    def pandas_op(operation: str, column: str|None=None, group_by: str|None=None,
                  filter_expr: str|None=None, top_n: int|None=10, rate_of: str|None=None):
        data = df_f.copy()
        if filter_expr:
            try:
                import re
                if not re.fullmatch(r"[A-Za-z0-9_ .><=!&|'\-\(\)]+", filter_expr):
                    return {"error":"Ø¹Ø¨Ø§Ø±Øª ÙÛŒÙ„ØªØ± Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª."}
                data = data.query(filter_expr)
            except Exception as e:
                return {"error": f"Ø®Ø·Ø§ Ø¯Ø± ÙÛŒÙ„ØªØ±: {e}"}
        try:
            if operation in ["mean","median","sum","count"] and column:
                if operation=="count":
                    val = int(data[column].shape[0]) if column not in data else int(data[column].count())
                else:
                    val = float(getattr(data[column], operation)())
                return {"result": val}
            if operation == "describe" and column:
                return {"table": data[column].describe().to_dict()}
            if operation == "group_mean" and column and group_by:
                tbl = data.groupby(group_by)[column].mean().reset_index().sort_values(column, ascending=False)
                fig = px.bar(tbl.head(top_n), x=group_by, y=column, title=f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† {column} Ø¨Ù‡ ØªÙÚ©ÛŒÚ© {group_by}")
                return {"table": tbl.head(top_n), "fig_json": fig.to_json()}

            if operation == "value_counts" and column:
                vc = data[column].astype(str).value_counts().head(top_n).to_frame("count")
                return {"table": vc.reset_index().rename(columns={"index":column})}
            if operation == "group_mean" and column and group_by:
                tbl = data.groupby(group_by)[column].mean().reset_index().sort_values(column, ascending=False)
                return {"table": tbl.head(top_n)}
            if operation == "attrition_rate_by" and group_by:
                if "_Attrition" not in data.columns: return {"error":"Ø³ØªÙˆÙ† _Attrition Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ù†ÛŒØ³Øª."}
                tbl = data.groupby(group_by)["_Attrition"].mean().reset_index().sort_values("_Attrition", ascending=False)
                tbl["_Attrition"] = (tbl["_Attrition"]*100).round(2)
                return {"table": tbl.head(top_n), "note":"Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø§Ø³Øª."}
            if operation in ["preview","filter_preview"]:
                return {"table": data.head(min(top_n or 10, 50))}
            return {"error":"Ø¹Ù…Ù„ÛŒØ§Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯."}
        except Exception as e:
            return {"error": f"Ø®Ø·Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª: {e}"}

    tools = [{
        "type": "function",
        "function": {
            "name": "pandas_op",
            "description": "Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø±ÙˆÛŒ df_f (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†/Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ/Ù†Ø±Ø® Attrition Ùˆ ...)",
            "parameters": {
                "type": "object",
                "properties": {
                    "operation": {"type": "string",
                        "enum": ["mean","median","sum","count","describe","value_counts",
                                 "group_mean","attrition_rate_by","preview","filter_preview"]},
                    "column": {"type":"string"}, "group_by": {"type":"string"},
                    "filter_expr": {"type":"string"}, "top_n": {"type":"integer","default":10},
                    "rate_of": {"type":"string"}
                }, "required": ["operation"]
            }
        }
    }]

    # replay history
    for role, content in st.session_state.chat_history_fc:
        with st.chat_message("assistant" if role=="assistant" else "user"):
            st.markdown(content)

    user_msg = st.chat_input("Ø³Ø¤Ø§Ù„ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ/ØªØ­Ù„ÛŒÙ„ÛŒâ€ŒØ§Øª Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³â€¦")
    if user_msg:
        with st.chat_message("user"): st.markdown(user_msg)

        def data_context_brief(df_ctx: pd.DataFrame) -> str:
            ctx = {"columns": list(df_ctx.columns),
                   "shape": list(df_ctx.shape),
                   "examples": df_ctx.head(3).to_dict(orient="records"),
                   "notes": "Ø³ØªÙˆÙ† Ù‡Ø¯Ù Ø¨Ø§ÛŒÙ†Ø±ÛŒ: _Attrition (1=Leave, 0=Stay)"}
            return json.dumps(ctx, ensure_ascii=False)

        messages = [
            {"role":"system","content":
             "ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒ. Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø´Ø§Ù…Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø³ØªØŒ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± pandas_op Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†. "
             "Ø¹Ø¯Ø¯ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø¯Ù‡ Ùˆ Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† ÛŒÚ© Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ú©Ù†."},
            {"role":"user","content": "Data context (JSON): " + data_context_brief(df_f)}
        ]
        for role, content in st.session_state.chat_history_fc[-6:]:
            messages.append({"role": role, "content": content})
        messages.append({"role":"user","content": user_msg})

        resp = client.chat.completions.create(
            model="gpt-4o-mini", messages=messages, tools=tools,
            tool_choice="auto", temperature=0.2, max_tokens=600
        )
        tool_calls = getattr(resp.choices[0].message, "tool_calls", None)
        final_answer = None

        if tool_calls:
            for tc in tool_calls:
                if tc.function.name == "pandas_op":
                    try: args = json.loads(tc.function.arguments or "{}")
                    except Exception: args = {}
                    result = pandas_op(**args)
                    if isinstance(result, dict) and "table" in result:
                        tbl = result["table"]
                        if isinstance(tbl, dict): tbl = pd.DataFrame([tbl])
                        st.dataframe(tbl, use_container_width=True)
                        if isinstance(result, dict) and "fig_json" in result:
                            fig = pio.from_json(result["fig_json"])
                            st.plotly_chart(fig, use_container_width=True)

                    follow_messages = messages + [resp.choices[0].message, {
                        "role": "tool", "tool_call_id": tc.id, "name": "pandas_op",
                        "content": json.dumps(result, ensure_ascii=False, default=str)
                    }]
                    resp2 = client.chat.completions.create(
                        model="gpt-4o-mini", messages=follow_messages,
                        temperature=0.2, max_tokens=600
                    )
                    final_answer = resp2.choices[0].message.content
                    break
        else:
            final_answer = resp.choices[0].message.content

        if not final_answer: final_answer = "Ù†ØªÙˆØ§Ù†Ø³ØªÙ… Ù¾Ø§Ø³Ø®ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ù…."
        with st.chat_message("assistant"): st.markdown(final_answer)
        st.session_state.chat_history_fc += [("user", user_msg), ("assistant", final_answer)]

    c1, c2 = st.columns(2)
    if c1.button("ğŸ§¹ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡"):
        st.session_state.chat_history_fc = []; st.rerun()
    if c2.button("ğŸ” Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯"):
        st.info("Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ù†ØŸ | Ù†Ø±Ø® Attrition Ø¨Ù‡ ØªÙÚ©ÛŒÚ© DepartmentØŸ | Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ù‚ÙˆÙ‚ Ø¯Ø± SalesØŸ | 10 Ø´ØºÙ„Ù Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø­Ù‚ÙˆÙ‚ØŸ")


# ===================== Page 8: What-If =====================

elif page == "What-If":
    st.subheader("ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ (What-If)")
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
    model = None
    for p in [MODEL_PATH, "best_model.joblib"]:
        if os.path.exists(p):
            try:
                model = load(p); break
            except Exception:
                pass
    if model is None:
        st.warning("Ù…Ø¯Ù„ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ø§Ø¨ØªØ¯Ø§ ØµÙØ­Ù‡ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†.")
        st.stop()

    colA, colB = st.columns(2)
    sal_up = colA.slider("Ø§ÙØ²Ø§ÛŒØ´ Ø­Ù‚ÙˆÙ‚ (%)", 0, 50, 10, 5)
    ot_down = colB.slider("Ú©Ø§Ù‡Ø´ Ù†Ø±Ø® OverTime (%)", 0, 100, 20, 5)

    base = df_f.copy()
    scen = base.copy()
    if "MonthlyIncome" in scen:
        scen["MonthlyIncome"] = scen["MonthlyIncome"] * (1 + sal_up/100.0)
    if "OverTime" in scen:
        yes_idx = scen["OverTime"].astype(str) == "Yes"
        to_flip = int(yes_idx.sum() * (ot_down/100.0))
        if to_flip > 0:
            flip_idx = scen[yes_idx].sample(to_flip, random_state=RANDOM_STATE).index
            scen.loc[flip_idx, "OverTime"] = "No"

    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø±Ø® Attrition Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯
    def _proba_mean(m, data):
        prep = m.named_steps.get("prep"); cols = list(prep.feature_names_in_)
        X = data.copy()
        if "Attrition" in X: X = X.drop(columns=["Attrition"])
        for c in cols:
            if c not in X: X[c] = np.nan
        X = X[cols]
        return m.predict_proba(X)[:, 1].mean()

    base_rate = _proba_mean(model, base)
    scen_rate = _proba_mean(model, scen)

    cmp_df = pd.DataFrame({
        "Scenario": ["Baseline", "New"],
        "Expected Attrition (%)": [base_rate*100, scen_rate*100]
    })
    fig_s = px.bar(cmp_df, x="Scenario", y="Expected Attrition (%)", text="Expected Attrition (%)",
                   title="ØªØ£Ø«ÛŒØ± Ø³Ù†Ø§Ø±ÛŒÙˆ Ø¨Ø± Attrition (Ù…Ø¯Ù„)")
    fig_s.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
    st.plotly_chart(fig_s, use_container_width=True)

# ===================== Page 9: Cohorts =====================
elif page == "Cohorts":
    st.subheader("ØªØ­Ù„ÛŒÙ„ Ú¯Ø±ÙˆÙ‡ÛŒ (Cohort)")
    if {"Age","YearsAtCompany","_Attrition"}.issubset(df_f.columns):
        age_bin = st.slider("Ø¨Ø§Ø²Ù‡ Ø³Ù†ÛŒ (Ø³Ø§Ù„)", 5, 15, 10, 1)
        ten_bin = st.slider("Ø¨Ø§Ø²Ù‡ Ø³Ø§Ø¨Ù‚Ù‡ (Ø³Ø§Ù„)", 1, 10, 3, 1)
        dfc = df_f.copy()
        dfc["AgeBand"] = pd.cut(dfc["Age"],
                                bins=range(int(dfc["Age"].min()), int(dfc["Age"].max())+age_bin, age_bin),
                                right=False)
        dfc["TenureBand"] = pd.cut(dfc["YearsAtCompany"],
                                   bins=range(0, int(dfc["YearsAtCompany"].max())+ten_bin, ten_bin),
                                   right=False)
        coh = dfc.groupby(["AgeBand","TenureBand"])["_Attrition"].mean().reset_index()
        coh["_Attrition"] = (coh["_Attrition"]*100).round(1)
        coh_piv = coh.pivot(index="AgeBand", columns="TenureBand", values="_Attrition")
        fig_coh = go.Figure(go.Heatmap(
            z=coh_piv.values,
            x=[str(c) for c in coh_piv.columns],
            y=[str(i) for i in coh_piv.index],
            colorscale="YlOrRd",
            hovertemplate="Age=%{y}<br>Tenure=%{x}<br>Rate=%{z:.1f}%<extra></extra>"
        ))
        fig_coh.update_layout(title="Attrition Cohort Heatmap (%)", height=560)
        st.plotly_chart(fig_coh, use_container_width=True)
    else:
        st.info("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Age/YearsAtCompany/_Attrition Ù„Ø§Ø²Ù… Ø§Ø³Øª.")


